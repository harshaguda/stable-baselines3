{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CustomFeaturesExtractor' from 'stable_baselines3.ppo.custom_policies' (/home/irobotics/stable-baselines3/stable_baselines3/ppo/custom_policies.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VecFrameStack\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msac\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_policies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomActor, CustomContinousCritic, CustomSACPolicy\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_policies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomActorCriticPolicy, CustomNetwork, CustomFeaturesExtractor\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CustomFeaturesExtractor' from 'stable_baselines3.ppo.custom_policies' (/home/irobotics/stable-baselines3/stable_baselines3/ppo/custom_policies.py)"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, Tuple, Union\n",
    "from stable_baselines3.common.type_aliases import GymStepReturn\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pytest\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces.space import Space\n",
    "\n",
    "\n",
    "from stable_baselines3 import SAC, A2C, PPO\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.sac.custom_policies import CustomActor, CustomContinousCritic, CustomSACPolicy\n",
    "from stable_baselines3.ppo.custom_policies import CustomActorCriticPolicy, CustomNetwork, CustomFeaturesExtractor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeImageEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Fake image environment for testing purposes, it mimics Atari games.\n",
    "\n",
    "    :param action_dim: Number of discrete actions\n",
    "    :param screen_height: Height of the image\n",
    "    :param screen_width: Width of the image\n",
    "    :param n_channels: Number of color channels\n",
    "    :param discrete: Create discrete action space instead of continuous\n",
    "    :param channel_first: Put channels on first axis instead of last\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        action_dim: int = 6,\n",
    "        screen_height: int = 64,\n",
    "        screen_width: int = 64,\n",
    "        n_channels: int = 3,\n",
    "        discrete: bool = False,\n",
    "        channel_first: bool = False,\n",
    "    ) -> None:\n",
    "        self.observation_shape = (screen_height, screen_width, n_channels)\n",
    "        if channel_first:\n",
    "            self.observation_shape = (n_channels, screen_height, screen_width)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=self.observation_shape, dtype=np.uint8)\n",
    "        if discrete:\n",
    "            self.action_space = spaces.Discrete(action_dim)\n",
    "        else:\n",
    "            self.action_space = spaces.Box(low=-1, high=1, shape=(action_dim,), dtype=np.float32)\n",
    "        self.ep_length = 10\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[Dict] = None) -> Tuple[np.ndarray, Dict]:\n",
    "        if seed is not None:\n",
    "            super().reset(seed=seed)\n",
    "        self.current_step = 0\n",
    "        return self.observation_space.sample(), {}\n",
    "\n",
    "    def step(self, action: Union[np.ndarray, int]) -> GymStepReturn:\n",
    "        reward = 0.0\n",
    "        self.current_step += 1\n",
    "        terminated = False\n",
    "        truncated = self.current_step >= self.ep_length\n",
    "        return self.observation_space.sample(), reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self, mode: str = \"human\") -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1,3,64,64).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irobotics/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/irobotics/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = PPO(CustomActorCriticPolicy, env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomFeaturesExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m FakeImageEnv(discrete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m policy_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m----> 3\u001b[0m     features_extractor_class\u001b[38;5;241m=\u001b[39m\u001b[43mCustomFeaturesExtractor\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# features_extractor_kwargs=dict(features_dim=128),\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(CustomActorCriticPolicy, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomFeaturesExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "env = FakeImageEnv(discrete=True)\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomFeaturesExtractor,\n",
    "    # features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "model = PPO(CustomActorCriticPolicy, env, verbose=1, policy_kwargs=policy_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomFeaturesExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mfeatures_extractor_class \u001b[38;5;241m=\u001b[39m \u001b[43mCustomFeaturesExtractor\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomFeaturesExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "model.policy.features_extractor_class = CustomFeaturesExtractor\n",
    "model.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5], device='cuda:0'),\n",
       " tensor([[-0.0103]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([-1.7910], device='cuda:0', grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1114     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f7ce140b010>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = model.policy.mlp_extractor(torch.randn(1,3,64,64).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6942, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3737,\n",
       "         0.4267, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6754,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.8732, 0.0000, 0.0000, 1.6379,\n",
       "         0.0000, 0.0000, 0.0000, 1.5004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.5894, 1.4374, 0.7901, 0.0000, 0.0000, 0.0000, 0.8521, 0.1529, 0.0000,\n",
       "         0.3006, 0.0000, 0.0000, 0.1547, 0.0000, 0.0000, 0.0000, 0.0000, 1.8882,\n",
       "         0.0000, 0.8816, 0.7326, 0.6156, 2.6843, 0.1397, 0.0000, 0.0000, 1.0876,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 1.9841, 0.0000, 1.4970, 0.8682, 1.1011,\n",
       "         0.0000, 0.6987, 1.1340, 0.0000, 3.7269, 2.3969, 0.0000, 0.0000, 0.4092,\n",
       "         1.3309, 0.0000, 1.9305, 0.0000, 0.0000, 1.8371, 0.0000, 0.4794, 1.7046,\n",
       "         0.0572, 0.1056, 0.9772, 1.6199, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 1.7156, 0.0000, 0.0000, 0.0000, 0.4432, 0.0000,\n",
       "         0.0000, 1.0726, 1.7206, 2.1367, 1.2280, 0.2115, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3187, 0.5881, 0.6050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 1.2379, 0.0000, 1.3609, 0.1164, 0.6273, 0.0000,\n",
       "         0.0000, 0.0000, 2.0229, 0.5175, 0.0000, 1.9778, 0.2155, 0.3931, 0.1796,\n",
       "         0.0000, 0.0000, 1.3242, 0.0000, 1.1210, 0.0000, 1.0986, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 1.6648, 0.0000, 1.7353, 1.0074, 0.8066, 1.2035,\n",
       "         0.0000, 0.0775, 0.0000, 1.2732, 0.0000, 0.2961, 0.0000, 0.2611, 0.0000,\n",
       "         0.0000, 0.0000, 0.2184, 0.0000, 0.0000, 0.6163, 0.0000, 0.6154, 0.0000,\n",
       "         0.2893, 1.0253, 0.0000, 0.0000, 1.6854, 0.3953, 0.3235, 0.0000, 0.4525,\n",
       "         0.9400, 2.1716, 0.0000, 0.5523, 0.0000, 0.0000, 0.0000, 0.0000, 0.4695,\n",
       "         0.0000, 0.0000, 1.7687, 0.0000, 1.2163, 0.4081, 0.0000, 0.0000, 1.3774,\n",
       "         1.3512, 0.0000, 1.4481, 0.0000, 1.8150, 0.0000, 0.3558, 0.0000, 0.0000,\n",
       "         0.5194, 0.4055, 0.0000, 0.0000, 1.4188, 0.8310, 0.0000, 0.0994, 0.5430,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2091, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.7302, 0.0000, 1.2083, 0.4540, 1.7162, 0.0000, 0.7788, 0.0000, 0.0000,\n",
       "         0.0000, 0.0437, 1.9351, 2.1925, 0.8168, 0.0000, 0.0000, 0.7983, 2.2745,\n",
       "         0.3379, 0.2885, 1.5416, 0.0000, 0.0000, 0.0000, 0.6731, 0.0527, 0.0105,\n",
       "         1.7293, 0.2207, 0.0000, 0.0000, 1.5725, 1.3913, 0.0000, 1.8353, 3.1586,\n",
       "         0.0000, 0.7110, 0.0000, 1.7862, 0.0000, 3.1178, 0.2041, 0.3749, 0.9173,\n",
       "         0.3778, 0.0225, 0.0000, 3.5233, 1.6279, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.7465, 0.8440, 0.0000, 2.6163, 0.9688, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 1.0922, 0.0000, 0.0000, 0.0000, 0.0000, 1.7898, 0.9237, 3.1350,\n",
       "         0.5997, 1.8964, 0.0000, 0.0000, 0.0000, 0.9988, 0.0000, 0.0000, 1.3612,\n",
       "         0.0000, 1.0876, 1.0145, 0.4666, 0.1027, 0.4594, 0.0000, 0.3184, 0.7077,\n",
       "         0.1581, 0.3930, 0.0000, 0.0000, 1.0848, 0.6543, 0.0000, 0.0117, 0.0000,\n",
       "         0.0000, 0.5996, 0.9021, 0.0047, 0.0000, 0.0000, 0.0000, 0.0000, 2.2181,\n",
       "         0.8214, 1.8865, 0.6913, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.5044, 1.3813, 0.8152, 2.5678, 0.0000, 0.0000, 0.1124, 1.4309, 0.7069,\n",
       "         0.0000, 1.0033, 0.0000, 0.0000, 1.3861, 0.0000, 0.1979, 0.0000, 0.0000,\n",
       "         1.8447, 1.6530, 0.5720, 1.9845, 0.0984, 0.0000, 0.9180, 0.0000, 0.0000,\n",
       "         1.5927, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5867, 0.0000, 0.0067,\n",
       "         0.0000, 0.2711, 3.4358, 0.0000, 0.0000, 2.0158, 0.0000, 0.0000, 0.0000,\n",
       "         0.2156, 0.0000, 0.6999, 1.6790, 0.1767, 0.0000, 0.0000, 0.0000, 1.1545,\n",
       "         0.0000, 0.8134, 0.6896, 0.0000, 0.6158, 1.4423, 0.7858, 0.2016, 0.0000,\n",
       "         0.7051, 0.0000, 1.2975, 0.2292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         3.1609, 0.3178, 0.0000, 0.8037, 3.1012, 0.5853, 0.0000, 0.0000, 0.4067,\n",
       "         2.6453, 0.0117, 0.0000, 0.5192, 0.0000, 0.0000, 0.0000, 3.4337, 0.0000,\n",
       "         0.2006, 1.2001, 0.2858, 0.0000, 2.1855, 0.5345, 0.6180, 0.0000, 0.0000,\n",
       "         0.0000, 0.3220, 1.9586, 0.0000, 0.0000, 2.0471, 0.0000, 0.9970, 0.0000,\n",
       "         3.1705, 0.2577, 0.4621, 0.2640, 1.0418, 0.0000, 0.0000, 0.5624, 0.0000,\n",
       "         0.5062, 0.0000, 2.3966, 0.0000, 1.2120, 0.0000, 0.9410, 2.0096, 0.0096,\n",
       "         0.6486, 0.0000, 0.0435, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.8863, 0.0000, 0.0000, 1.6164, 0.3791, 1.7182, 0.0000, 0.0000, 0.9538,\n",
       "         0.8092, 0.8901, 1.1059, 0.0000, 1.0149, 0.0000, 0.7981, 4.4944, 0.8218,\n",
       "         0.0000, 0.0000, 0.9630, 0.9365, 0.8237, 0.0000, 2.6465, 0.0000]],\n",
       "       device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.features_extractor(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (192x64 and 512x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/stable-baselines3/stable_baselines3/common/policies.py:651\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    649\u001b[0m     latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_critic(vf_features)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[1;32m    652\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n\u001b[1;32m    653\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/stable-baselines3/sb3-dev/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (192x64 and 512x1)"
     ]
    }
   ],
   "source": [
    "model.policy(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f96495b6860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model#.policy.mlp_extractor.policy_net.forward(torch.randn(1,3,64,64).to(\"cuda\"))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 1209     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 40       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 1213     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 80       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irobotics/stable-baselines3/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 24.61GB > 19.96GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 120      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.35    |\n",
      "|    critic_loss     | 0.137    |\n",
      "|    ent_coef        | 0.995    |\n",
      "|    ent_coef_loss   | -0.0546  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 160      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.22    |\n",
      "|    critic_loss     | 0.118    |\n",
      "|    ent_coef        | 0.983    |\n",
      "|    ent_coef_loss   | -0.176   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 59       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 200      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.02    |\n",
      "|    critic_loss     | 0.0918   |\n",
      "|    ent_coef        | 0.971    |\n",
      "|    ent_coef_loss   | -0.298   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 54       |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 240      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.13    |\n",
      "|    critic_loss     | 0.0772   |\n",
      "|    ent_coef        | 0.959    |\n",
      "|    ent_coef_loss   | -0.418   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 139      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 280      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.32    |\n",
      "|    critic_loss     | 0.106    |\n",
      "|    ent_coef        | 0.948    |\n",
      "|    ent_coef_loss   | -0.54    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 179      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 320      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.5     |\n",
      "|    critic_loss     | 0.0585   |\n",
      "|    ent_coef        | 0.937    |\n",
      "|    ent_coef_loss   | -0.664   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 219      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 360      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.72    |\n",
      "|    critic_loss     | 0.109    |\n",
      "|    ent_coef        | 0.925    |\n",
      "|    ent_coef_loss   | -0.781   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 259      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 400      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.06    |\n",
      "|    critic_loss     | 0.0836   |\n",
      "|    ent_coef        | 0.914    |\n",
      "|    ent_coef_loss   | -0.906   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 299      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 440      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.37    |\n",
      "|    critic_loss     | 0.0601   |\n",
      "|    ent_coef        | 0.904    |\n",
      "|    ent_coef_loss   | -1.03    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 339      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 480      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.73    |\n",
      "|    critic_loss     | 0.0813   |\n",
      "|    ent_coef        | 0.893    |\n",
      "|    ent_coef_loss   | -1.15    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 379      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 520      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.3    |\n",
      "|    critic_loss     | 0.0877   |\n",
      "|    ent_coef        | 0.882    |\n",
      "|    ent_coef_loss   | -1.26    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 419      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 560      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.6    |\n",
      "|    critic_loss     | 0.0785   |\n",
      "|    ent_coef        | 0.872    |\n",
      "|    ent_coef_loss   | -1.39    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 459      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 600      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.2    |\n",
      "|    critic_loss     | 0.0628   |\n",
      "|    ent_coef        | 0.861    |\n",
      "|    ent_coef_loss   | -1.51    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 499      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 640      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.5    |\n",
      "|    critic_loss     | 0.0921   |\n",
      "|    ent_coef        | 0.851    |\n",
      "|    ent_coef_loss   | -1.63    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 539      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 680      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.9    |\n",
      "|    critic_loss     | 0.109    |\n",
      "|    ent_coef        | 0.841    |\n",
      "|    ent_coef_loss   | -1.75    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 579      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 0.0712   |\n",
      "|    ent_coef        | 0.831    |\n",
      "|    ent_coef_loss   | -1.87    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 619      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 760      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.7    |\n",
      "|    critic_loss     | 0.0943   |\n",
      "|    ent_coef        | 0.821    |\n",
      "|    ent_coef_loss   | -2       |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 659      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.1    |\n",
      "|    critic_loss     | 0.153    |\n",
      "|    ent_coef        | 0.811    |\n",
      "|    ent_coef_loss   | -2.12    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 840      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14      |\n",
      "|    critic_loss     | 0.124    |\n",
      "|    ent_coef        | 0.801    |\n",
      "|    ent_coef_loss   | -2.24    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 739      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 880      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.4    |\n",
      "|    critic_loss     | 0.092    |\n",
      "|    ent_coef        | 0.792    |\n",
      "|    ent_coef_loss   | -2.36    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 779      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 920      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.8    |\n",
      "|    critic_loss     | 0.158    |\n",
      "|    ent_coef        | 0.782    |\n",
      "|    ent_coef_loss   | -2.48    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 819      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 960      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.4    |\n",
      "|    critic_loss     | 0.0625   |\n",
      "|    ent_coef        | 0.773    |\n",
      "|    ent_coef_loss   | -2.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 859      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.7    |\n",
      "|    critic_loss     | 0.0612   |\n",
      "|    ent_coef        | 0.764    |\n",
      "|    ent_coef_loss   | -2.72    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 899      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f87f44503a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAC(\"CnnPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function stable_baselines3.common.utils.constant_fn.<locals>.func(_)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
